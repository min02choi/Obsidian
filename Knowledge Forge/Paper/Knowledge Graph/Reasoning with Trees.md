 논문 제목: Reasoning with Trees: Faithful Question Answering over Knowledge Graph
 *** 
### **1. Background (연구 배경)**

최근 대형 언어 모델(LLM)의 발전으로 인해 복잡한 추론 작업에서도 우수한 성능을 보이고 있지만, 다중 단계의 복잡한 추론 문제에서는 여전히 한계가 존재함. 특히, **환각(hallucination)** 문제로 인해 LLM이 신뢰할 수 없는 정보를 생성하는 경우가 많음. 이를 해결하기 위해 **지식 그래프(KG)** 를 활용한 접근 방식이 제안되었지만, 기존 방법들은 KG와 LLM을 효과적으로 통합하지 못하는 문제를 가짐.

---

### **2. Motivation & Idea (기존 연구 한계점 + 연구 동기 + 아이디어)**

#### **✅ 기존 연구의 한계**

1. **지식 그래프와 LLM의 비효율적인 통합**
    - LLM을 KG의 검색 도구 또는 쿼리 생성기로만 사용하여 **LLM 내부 지식과 외부 KG 정보를 효과적으로 결합하지 못함**.
2. **인간의 사고 과정(human intuitive erasoning)** 을 따르지 않음
3. **비효율적인 추론 과정**
    - 기존 KG 기반 질의응답(KGQA) 모델들은 LLM이 제공하는 내재적 지식을 활용하지 못하고, 탐색 경로를 정할 때 **비효율적인 검색 전략**을 사용함.
4. **hallucination 문제 해결 부족**
    - LLM의 hallucination 문제를 해결하기 위해 KG를 활용하더라도, LLM이 오류를 수정하고 새로운 정보를 반영하는 능력이 부족함.

#### **💡 연구 아이디어**

- **"Reasoning with Trees (RwT)"** 라는 새로운 프레임워크를 제안하여 **LLM과 KG를 동적으로 결합하는 방식으로 추론 성능과 해석 가능성을 향상**.
- KGQA 문제를 **이산적 의사 결정(discrete decision-making) 문제**로 재구성하고, **[[MCTS(Monte Carlo Tree Search)|Monte Carlo Tree Search]] (MCTS)** 를 활용하여 최적의 추론 경로를 찾음.
- LLM의 사전 학습된 지식을 활용하면서도, 외부 KG 정보를 동적으로 반영하여 **사람처럼 추론 과정을 반복적으로 수정하고 보완**하는 방식 적용.

---

### **3. Contribution (주요 기여점)**

1. **지식 그래프 기반의 신뢰할 수 있는 추론 방식 제안**
    - LLM과 KG를 **동적으로 결합**하여 신뢰할 수 있는 답변을 생성하는 **새로운 KGQA 프레임워크 "RwT"** 개발.
2. **Monte Carlo Tree Search (MCTS) 기반의 최적 탐색 전략 도입**
    - **LLM을 휴리스틱(heuristic) 가이드로 활용**하여, **MCTS를 통해 최적의 추론 경로를 학습**하도록 개선.
3. **실제 데이터 기반 평가 모델 적용**
    - KG 정보를 학습하는 **pre-trained 평가 모델**을 개발하여, **추론 과정의 품질을 자동으로 평가 및 개선**.
4. **최신 KGQA 벤치마크에서 SOTA 성능 달성**
    - **WebQuestionSP, Complex WebQuestions (CWQ) 데이터셋에서 기존 SOTA 대비 9.81% 성능 향상**을 보임.
    - **LLM 전체를 재훈련하지 않고**, 비교적 작은 평가 모델만 학습하여 성능을 극대화.

---

### **4. Method (방법론: Motivation과 Contribution과 연계하여 구체적으로 설명)**

![[Pasted image 20250228173739.png]]

**📌 RwT의 주요 구성 요소**

1. **Monte Carlo Tree Search (MCTS) 적용**
    - KGQA 문제를 **마르코프 결정 과정(MDP)** 으로 정의하고, **MCTS를 사용하여 최적의 검색 경로를 탐색**.
    - LLM을 **휴리스틱 정책 모델(policy model)** 로 사용하여, 탐색 과정에서 가장 유망한 경로를 선택하도록 설계.

2. **추론 과정에서 LLM과 KG 정보 동적 통합**
    - **LLM이 초기 후보 답변을 생성**한 후, KG를 활용해 이를 검증 및 수정.
    - MCTS를 사용하여 다양한 탐색 경로를 평가하고, **LLM의 사전 지식을 반영한 평가 모델**을 통해 품질을 향상.

3. **"Hop-Level Beam Search (HBS)" 기법 도입**
    - 다단계 추론 과정에서 연산량을 줄이기 위해 **Hop-Level Beam Search (HBS)** 를 적용하여 **효율적인 검색 수행**.


**RwT에서 사용된 모델 설명**
1. **정책 모델 (Policy Model)** – 사전 훈련된 LLM
	- **역할**: MCTS의 탐색 방향을 안내하는 역할
	- **특징**:
	    - 대형 언어 모델(LLM)로, 이미 사전 훈련되어 있음.
	    - 방대한 세계 지식과 일반적인 패턴을 학습한 상태.
	    - 직접 훈련되지 않으며, 고정된 상태에서 탐색 과정에서 가이드 역할을 함.

2. 평가 모델 (Evaluation Model) – 도메인 특화 지식을 반영하여 학습됨
	- **역할**: MCTS의 각 상태(state)를 평가하여 최적의 경로를 찾도록 도움. 두개의 하위 모델로 이루어져 있다.
	- **특징**:
	    - 비교적 작은 모델로, 효율성과 정확도를 동시에 고려하여 학습됨.
	    - LLM과 달리 도메인 특화 지식을 학습할 수 있도록 훈련됨.
	    - MCTS의 탐색을 보완하여 더 나은 결정을 내릴 수 있도록 지원함.

	**① 크리티컬 모델 (Critical Model)**
	- 특정 상태(state)의 품질을 평가하고, 탐색 과정에서 중요한 노드를 구별하는 역할을 함.
	- MCTS가 보다 중요한 경로를 우선 탐색하도록 가이드함.
	
	**② 롤아웃 모델 (Roll-out Model)**
	- MCTS에서 일종의 시뮬레이션을 수행하는 역할.
	- 현재 상태에서 임의의 경로를 따라가며 미래 보상을 예측하여, 탐색의 신뢰도를 높임.

---

### **5. Result (주요 분석 및 결과 해석)**

1. **벤치마크 테스트 성능 비교**
    - WebQSP 및 CWQ 데이터셋에서 기존 최신 모델보다 **9.81% 더 높은 성능**을 기록.
    - 특히 다중 단계(multi-hop) 추론이 필요한 CWQ 데이터셋에서 우수한 성능 발휘.

2. **다른 LLM과의 통합 성능 비교**
    - 기존 ChatGPT, GPT-4o, LLaMA2 등과 결합했을 때 **평균적으로 55.88%의 성능 향상**을 보여줌.
    - **LLM의 크기와 관계없이 RwT를 결합하면 성능이 크게 향상됨**, 특히 지식 그래프가 부족한 도메인에서도 효과적.

3. **Ablation Study 결과**
    - **MCTS, 평가 모델(Roll-out & Critical Model)을 함께 사용했을 때 가장 높은 성능을 기록**.
    - LLM 단독 사용 시 Hits@1 성능이 53.1%였으나, RwT를 적용하면 72.4%까지 향상됨.

---

### **6. 한계점 및 향후 연구 방향 (Limitations & Insights)**

1. **지식 그래프의 한계**
    - KG의 정보가 불완전하거나 모순될 경우, 성능이 저하될 가능성이 있음.
    - KG가 부족한 도메인에서의 성능을 개선하기 위해 **KG 자동 확장 또는 강화 학습 적용 필요**.
2. **범용성 문제**
    - 현재 RwT는 **일반적인 QA 벤치마크(WebQSP, CWQ)에서만 평가되었으며, 도메인 특화 KGQA 문제에는 확장되지 않음**.
    - 의학, 법률, 과학 논문 등 특정 도메인에 맞춘 KGQA 모델로 확장하는 연구가 필요.
3. **추론 과정의 계산량**
    - MCTS 기반 탐색은 기존보다 강력한 성능을 보이지만, **계산 비용이 상대적으로 높음**.
    - 이를 해결하기 위해 **Hop-Level Beam Search (HBS) 같은 경량화 기법을 추가 개발할 필요 있음**.

---

## **📌 결론 (Conclusion)**

- 본 연구는 **대형 언어 모델과 지식 그래프를 동적으로 결합하는 새로운 추론 프레임워크 RwT를 제안**함.
- MCTS 기반의 탐색 기법과 평가 모델을 활용하여 **LLM의 신뢰도를 높이고, 다중 단계의 복잡한 질문에도 강인한 성능을 발휘**.
- 기존 최신 방법들보다 **9.81% 향상된 정확도를 기록했으며**, 특히 **LLM을 전체 재훈련하지 않고도 성능을 개선할 수 있는 유연성을 제공**.
- 향후 연구로는 **다양한 도메인 지식 그래프에 대한 일반화 및 효율적인 추론 과정 개선이 필요**.