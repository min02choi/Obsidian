---
aliases:
  - SubgraphRAG
---
논문 제목: Simple Is Effective: The Roles of Graphs and Large Language Models in Knowledge-Graph-Based Retrieval-Augmented Generation
![[Pasted image 20250320145345.png]]

* 훈련 결과: [[SubgraphRAG|SubgraphRAG Train Log]]

***

### **1. 연구 배경 (Background)**

* 대형 언어 모델(LLM)은 강력한 추론 능력을 갖추고 있지만 **hallucination, 오래된 정보, 제한된 도메인 전문성** 등의 한계를 가지고 있음.  
* 이를 해결하기 위해 **지식 그래프(KG) 기반 검색 증강 생성([[RAG]], Retrieval-Augmented Generation)** 기법이 활용되지만, 현재의 KG 기반 RAG 프레임워크는 **효율적인 검색과 효과적인 정보 제공 사이의 균형을 맞추는 데 어려움**이 있음.  

즉, LLM이 소화할 수 있는 **최적의 양의 그래프 정보**를 찾는 것이 핵심 과제.

---

### **2. 연구 동기 & 기존 연구 한계점 (Motivation & Idea)**

#### **기존 연구의 한계점**

1. **비효율적인 검색 방법**
    - 기존 텍스트 기반 RAG는 **복잡한 추론을 처리하는 데 한계**가 있음.
    - 현재의 KG 기반 검색 방법들은 **여러 번의 LLM 호출을 필요**로 하며, 이는 계산 비용 증가로 이어짐.
    - 기존의 BM25나 밀집 검색(dense retrieval) 방식은 **그래프 구조를 효과적으로 반영하지 못함**.

2. **계산 비용 문제**
    - 실시간 질문에 대응하려면 **지식 그래프의 동적 업데이트를 효율적으로 처리할 수 있어야 함**.
    - 기존의 근사 최근접 이웃 검색(LSH, Locality-Sensitive Hashing) 기법은 **그래프 구조 검색에 적합하지 않음**.

3. **LLM의 한계 극복 필요**
    - LLM이 사용할 수 있는 **문맥 길이(window size)가 제한적**이며, **불필요한 정보를 포함하면 성능이 저하됨**.
    - 기존 연구에서는 **검색된 정보량이 지나치게 많거나 부족하여** 모델이 환각을 일으키거나 답변을 제대로 하지 못하는 경우가 많았음.

#### **아이디어

- **SubgraphRAG**이라는 새로운 KG 기반 RAG 프레임워크를 제안함.
- 핵심 아이디어: **필요한 정보만을 포함하는 서브그래프(subgraph)를 검색하여 LLM이 이를 활용하도록 함**.
- 기존 방법과 달리 **경량화된 다층 퍼셉트론(MLP)과 병렬적인 트리플 스코어링(triple-scoring) 기법**을 사용하여 검색 효율성을 높임.
- 방향성 구조 거리(Directional Structural Distance)를 활용하여 **검색된 서브그래프의 질을 향상**.
- 결과적으로, **소형 LLM(Llama3.1-8B)도 경쟁력 있는 성능을 내고, 대형 LLM(GPT-4o)은 기존 방식보다 더 정확한 답변을 생성**할 수 있음.

---

### **3. 주요 기여점 (Contribution)**

1. **SubgraphRAG: 서브그래프 중심의 KG 기반 RAG 설계**
    - 기존 방법과 달리, 검색 과정에서 **질문에 적합한 서브그래프만을 선택**하여 불필요한 정보 제거.
    - 검색된 서브그래프의 크기를 조정할 수 있어 **LLM의 문맥 길이 제한을 고려한 최적화 가능**.

2. **효율적인 검색 알고리즘 적용**
    - 가벼운 MLP와 **병렬 트리플 스코어링 기법**을 결합하여 **검색 속도를 기존 대비 획기적으로 개선**.
    - 기존 그래프 신경망(GNN) 기반 검색보다 더 빠르면서도 정확성이 유지됨.

3. **LLM을 활용한 고급 추론 가능**
    - **GPT-4o 및 Llama3.1-8B 같은 모델이 기존 방법보다 정확한 답변을 제공**.
    - 모델을 추가 학습(fine-tuning)하지 않고도 강력한 성능을 발휘할 수 있도록 설계됨.

4. **검색된 정보의 품질 개선**
    - 서브그래프 검색 과정에서 **방향성 구조 거리(Direction Distance Encoding)를 활용**, 의미적으로 연관된 정보를 더 효과적으로 추출.
    - 이를 통해 **불필요한 정보가 포함되지 않도록 하여 LLM이 보다 신뢰성 있는 답변을 생성할 수 있도록 함**.

---

### **4. 방법론 (Method)**

![[Pasted image 20250320160430.png]]
본 연구에서 제안하는 **SubgraphRAG 프레임워크**는 다음과 같은 과정으로 작동함.

 1. **질문에서 핵심 개체(Topic Entities) 추출**
	- 질문에서 핵심 개체를 식별하여 검색할 정보의 초점을 맞춤.

2. **서브그래프 검색 (Subgraph Retrieval)**
	- 기존의 전체 그래프 검색이 아닌, 필요한 정보만을 포함하는 서브그래프를 추출.
	- 검색 과정에서 **병렬 트리플 스코어링 기법**을 활용하여 속도를 극대화.
	- **방향성 구조 거리**(DDE, Directional Distance Encoding)를 적용하여 질문과 더 밀접한 정보를 찾음.

3. **LLM을 이용한 추론 (LLM-based Reasoning)**
	- 검색된 서브그래프를 LLM에 입력하여 질문에 대한 답변을 생성.
	- **서브그래프의 크기를 조정하여, LLM의 문맥 제한 내에서 최적의 성능을 유지**.

4. **최종 답변 생성 및 설명 제공**
	- **답변뿐만 아니라, LLM이 도출한 논리적인 설명을 함께 제공하여 신뢰성을 높임**.
	- 이를 통해 **LLM의 환각(hallucination) 문제를 줄이고, 실제 검색된 정보에 기반한 답변을 생성하도록 함**.

---

### **5. 주요 실험 결과 (Results & Analysis)**

#### **1️⃣ 검색 성능 개선 (Retrieval Performance)**

- **WebQSP, CWQ 데이터셋을 활용한 실험에서 SubgraphRAG가 기존 방법보다 높은 검색 성능을 기록**.
- 기존 RAG 모델 대비 **더 적은 계산 비용으로 더 높은 정확도를 달성**.

#### **2️⃣ KGQA(Knowledge Graph Question Answering) 성능**

- GPT-4o와 결합된 SubgraphRAG는 기존 모델 대비 **최고 수준의 정답률**을 보임.
- 소형 모델(Llama3.1-8B)도 SubgraphRAG를 활용하면 경쟁력 있는 성능을 유지할 수 있음.

#### **3️⃣ 설명 가능한 답변 제공 (Explainability)**

- 기존의 RAG 모델보다 **정확한 정보에 기반한 설명을 함께 제공**, 답변의 신뢰도를 높임.

---

### **6. 한계점 및 향후 연구 방향 (Limitation & Future Work)**

1. **추출된 서브그래프가 항상 최적이라고 보장할 수 없음**
    
    - LLM이 제공된 서브그래프만 활용하기 때문에 **정확한 정보가 포함되지 않을 경우, 성능 저하 가능성**이 있음.
2. **더 복잡한 멀티 홉 질문에서 추가적인 최적화 필요**
    
    - 여러 개의 토픽 엔티티가 포함된 질문에 대한 성능은 향후 더 개선될 필요가 있음.
3. **다양한 LLM 모델과의 조합 실험 부족**
    
    - GPT-4o에서 가장 좋은 성능을 보였으나, 다른 모델과의 최적 조합을 찾는 추가 연구가 필요함.

---

### **📌 결론**

본 연구는 KG 기반 RAG 모델의 새로운 방향을 제시하며, **기존 방법보다 더 빠르고 정확하며 효율적인 검색 및 추론이 가능함**을 입증함.

- **SubgraphRAG는 검색된 정보의 질을 향상시키면서, 소형 및 대형 LLM 모두에서 최적의 성능을 낼 수 있도록 설계됨**.
- 향후 연구에서는 **더 복잡한 질문에 대한 최적화 및 다양한 LLM 모델과의 조합 실험이 필요**함.